# -*- coding: utf-8 -*-
"""Titanic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qlYtzHj_EMK9t-5XKLVXUma1ztvCnni
"""

# Load Titanic dataset
import pandas as pd
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)

# Show first 5 rows
df.head()

# Shape of dataset (rows, columns)
print("Dataset shape:", df.shape)

# Column names
print("Columns:", df.columns)

# Summary statistics
df.describe()

# Check which columns have missing values
df.isnull().sum()

sns.countplot(x='Survived', data=df)
plt.title("Survived vs Not Survived")
plt.show()

df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])
df.head()

# Fill Age
df['Age'].fillna(df['Age'].median(), inplace=True)

# Fill Embarked
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Check again for missing values
df.isnull().sum()

df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})
df.head()

X = df.drop(columns='Survived')
y = df['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LogisticRegression

# Create the model
model = LogisticRegression(max_iter=1000)

# Train the model
model.fit(X_train, y_train)

print("Model trained successfully!")

# Predict on test data
y_pred = model.predict(X_test)

# Compare predictions with actual
print("Predicted values:", y_pred[:10])
print("Actual values   :", y_test.values[:10])

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:\n", cm)

# Detailed Classification Report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Example: 30-year-old female, 1st class, no siblings/parents, fare 70, embarked from S
new_passenger = pd.DataFrame({
    'Pclass': [1],
    'Sex': [1],
    'Age': [30],
    'SibSp': [0],
    'Parch': [0],
    'Fare': [70],
    'Embarked': [2]
})

prediction = model.predict(new_passenger)
print("Predicted Survival (0=No, 1=Yes):", prediction[0])

# Get feature importance
importance = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': model.coef_[0]
})

# Sort by absolute importance
importance['AbsCoeff'] = importance['Coefficient'].abs()
importance = importance.sort_values(by='AbsCoeff', ascending=False)

print(importance)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
sns.barplot(x='Coefficient', y='Feature', data=importance, palette='viridis')
plt.title("Feature Importance in Predicting Survival")
plt.show()

sns.countplot(x='Sex', hue='Survived', data=df)
plt.title("Survival by Gender (0=Male,1=Female)")
plt.show()

sns.countplot(x='Pclass', hue='Survived', data=df)
plt.title("Survival by Ticket Class")
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(df[df['Survived']==1]['Age'], color='green', label='Survived', kde=True, bins=20)
sns.histplot(df[df['Survived']==0]['Age'], color='red', label='Did Not Survive', kde=True, bins=20)
plt.xlabel("Age")
plt.title("Age Distribution of Survivors vs Non-Survivors")
plt.legend()
plt.show()